import os
import time
import json
import dill  # Th√™m th∆∞ vi·ªán n√†y
import pandas as pd # Th√™m pandas
from sklearn.feature_extraction.text import TfidfVectorizer # Th√™m sklearn
from sklearn.metrics.pairwise import cosine_similarity      # Th√™m sklearn

from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from dotenv import load_dotenv

# --- IMPORTS CHO AI & LANGCHAIN ---
from pinecone import Pinecone
from transformers import pipeline
from sentence_transformers import SentenceTransformer
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda, RunnablePassthrough

# --- C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N ---
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir) 

DOTENV_PATH = os.path.join(parent_dir, '.env')
# ƒê·∫£m b·∫£o file pickle n·∫±m ƒë√∫ng v·ªã tr√≠ n√†y
PICKLE_FILE_PATH = os.path.join(parent_dir, 'movie_recommender_2.pkl') 

load_dotenv(dotenv_path=DOTENV_PATH)
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

if not PINECONE_API_KEY or not GOOGLE_API_KEY:
    raise ValueError("Vui l√≤ng ki·ªÉm tra file .env, thi·∫øu API KEY!")

# ==============================================================================
# 1. ƒê·ªäNH NGHƒ®A CLASS MOVIE RECOMMENDER (B·∫Øt bu·ªôc ƒë·ªÉ load pickle)
# ==============================================================================
class MovieRecommender:
    def __init__(self, data_path):
        # ƒê·ªçc d·ªØ li·ªáu
        self.df = pd.read_csv(data_path)
        
        # X·ª≠ l√Ω genres v√† keywords th√†nh chu·ªói
        self.df['string'] = self.df.apply(self.genres_and_keywords_to_string, axis=1)
        
        # T·∫°o TF-IDF vectorizer v√† fit-transform d·ªØ li·ªáu
        self.tfidf = TfidfVectorizer(max_features=2000)
        self.X = self.tfidf.fit_transform(self.df['string'])
        
        # T·∫°o Series ƒë·ªÉ d·ªÖ d√†ng truy xu·∫•t movie index
        self.movie_idx = pd.Series(self.df.index, index=self.df['title'])
    
    @staticmethod
    def genres_and_keywords_to_string(row):
        genres = json.loads(row['genres'])
        genres = ' '.join(''.join(j['name'].split()) for j in genres)

        keywords = json.loads(row['keywords'])
        keywords = ' '.join(''.join(j['name'].split()) for j in keywords)
        return "%s %s" % (genres, keywords)
    
    def recommend(self, title):
        if title not in self.movie_idx:
            return None # Tr·∫£ v·ªÅ None ƒë·ªÉ API x·ª≠ l√Ω th√¥ng b√°o l·ªói
        else:
            idx = self.movie_idx[title]
            if type(idx) == pd.Series:  # Ki·ªÉm tra xem c√≥ nhi·ªÅu phim tr√πng t√™n kh√¥ng
                idx = idx.iloc[0]
            
            query = self.X[idx]
            scores = cosine_similarity(query, self.X)
            scores = scores.flatten()
            recommended_idx = (-scores).argsort()[1:6]
            return self.df['title'].iloc[recommended_idx]

# ==============================================================================
# 2. KH·ªûI T·∫†O FLASK & LOAD MODELS
# ==============================================================================
app = Flask(__name__)
CORS(app)

print("--- ƒêANG KH·ªûI T·∫†O H·ªÜ TH·ªêNG ---")

# A. Pinecone
pc = Pinecone(api_key=PINECONE_API_KEY)
index_name = "movies"
index = pc.Index(index_name)
print(f"‚úÖ ƒê√£ k·∫øt n·ªëi Pinecone Index: {index_name}")

# B. Translation Model
print("‚è≥ ƒêang t·∫£i model d·ªãch thu·∫≠t...")
TRANSLATION_MODEL = "Helsinki-NLP/opus-mt-vi-en"
translator = pipeline("translation", model=TRANSLATION_MODEL)
print("‚úÖ Model d·ªãch thu·∫≠t s·∫µn s√†ng.")

# C. Embedding Model
print("‚è≥ ƒêang t·∫£i model Embedding...")
embedding_model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-mpnet-base-v2")
print("‚úÖ Model Embedding s·∫µn s√†ng.")

# D. LLM (Gemini)
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", google_api_key=GOOGLE_API_KEY, temperature=0.7)

# E. TF-IDF Recommender (Ph·∫ßn m·ªõi th√™m)
print("‚è≥ ƒêang t·∫£i model TF-IDF (Pickle)...")
movie_recommender = None
try:
    if os.path.exists(PICKLE_FILE_PATH):
        with open(PICKLE_FILE_PATH, 'rb') as file:
            movie_recommender = dill.load(file)
        print("‚úÖ Model TF-IDF ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng.")
    else:
        print(f"‚ö†Ô∏è C·∫¢NH B√ÅO: Kh√¥ng t√¨m th·∫•y file {PICKLE_FILE_PATH}")
except Exception as e:
    print(f"‚ùå L·ªói khi t·∫£i file pickle: {str(e)}")
    # N·∫øu l·ªói, movie_recommender s·∫Ω l√† None

# ==============================================================================
# 3. CHAIN LANGCHAIN (Gi·ªØ nguy√™n)
# ==============================================================================
def translate_query(vietnamese_query):
    if not vietnamese_query: return ""
    print(f"[PROCESS] 1. D·ªãch: '{vietnamese_query}'")
    translated_result = translator(vietnamese_query)
    english_query = translated_result[0]['translation_text']
    print(f"   -> K·∫øt qu·∫£: '{english_query}'")
    return english_query

def get_embedding(english_query):
    print(f"[PROCESS] 2. T·∫°o Vector")
    return embedding_model.encode(english_query).tolist()

def query_pinecone(query_embedding):
    print("[PROCESS] 3. Truy v·∫•n Pinecone")
    results = index.query(
        vector=query_embedding,
        top_k=5,
        include_metadata=True
    )
    return results['matches']

def format_context_from_pinecone(matches):
    print("[PROCESS] 4. Format Context")
    if not matches:
        return ""
    
    context = ""
    for i, match in enumerate(matches):
        score = match['score']
        metadata = match.get('metadata', {})
        title = metadata.get('title', 'N/A')
        genres = metadata.get('genres', 'Kh√¥ng r√µ')
        overview = metadata.get('overview', 'Kh√¥ng c√≥ t√≥m t·∫Øt.')
        
        context += f"--- Phim {i+1} ---\n"
        context += f"Ti√™u ƒë·ªÅ: {title}\n"
        context += f"ƒêi·ªÉm t∆∞∆°ng ƒë·ªìng: {score:.2f}\n"
        context += f"Th·ªÉ lo·∫°i: {genres}\n"
        context += f"T√≥m t·∫Øt: {overview}\n\n"
    print(context)
    return context

translate_step = RunnableLambda(translate_query)
embed_step = RunnableLambda(get_embedding)
query_pinecone_step = RunnableLambda(query_pinecone)
augmentation_step = RunnableLambda(format_context_from_pinecone)

retrieval_chain = (translate_step | embed_step | query_pinecone_step | augmentation_step)

prompt_template = """
B·∫°n l√† m·ªôt tr·ª£ l√Ω t∆∞ v·∫•n phim ·∫£nh chuy√™n nghi·ªáp.
Ng∆∞·ªùi d√πng ƒëang t√¨m ki·∫øm phim v·ªõi m√¥ t·∫£: "{question}"

ƒê√¢y l√† danh s√°ch c√°c phim ph√π h·ª£p nh·∫•t t√¨m th·∫•y t·ª´ c∆° s·ªü d·ªØ li·ªáu:
{context}

**NHI·ªÜM V·ª§:**
N·∫øu kh√¥ng c√≥ phim n√†o trong danh s√°ch (context r·ªóng), h√£y xin l·ªói ng∆∞·ªùi d√πng.
N·∫øu c√≥ phim, h√£y vi·∫øt c√¢u tr·∫£ l·ªùi th√¢n thi·ªán b·∫±ng Ti·∫øng Vi·ªát:
1. X√°c nh·∫≠n nhu c·∫ßu t√¨m ki·∫øm c·ªßa h·ªç.
3. V·ªõi m·ªói phim, n√™u r√µ: T√™n phim, Th·ªÉ lo·∫°i, T√≥m t·∫Øt ng·∫Øn v√† L√ù DO t·∫°i sao n√≥ ph√π h·ª£p.
N·∫øu phim n√†o c√≥ ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng d∆∞·ªõi 0.6 th√¨ tr·∫£ l·ªùi kh√¥ng.
H√£y tr·∫£ l·ªùi ng·∫Øn g·ªçn, s√∫c t√≠ch v√† tr√¨nh b√†y ƒë·∫πp (d√πng Markdown).
"""
prompt = ChatPromptTemplate.from_template(prompt_template)
parser = StrOutputParser()

rag_chain = ({"context": retrieval_chain, "question": RunnablePassthrough()} | prompt | llm | parser)

# ==============================================================================
# 4. API ENDPOINTS
# ==============================================================================

@app.route('/chat', methods=['POST'])
def chat():
    try:
        data = request.json
        raw_query = data.get('query', '')
        
        print(f"\nüì© Nh·∫≠n request: {raw_query}")

        response_text = ""
        tool_used = "none"

        # --- MODE 1: SEMANTIC SEARCH (RAG) ---
        if "[MODE: SEMANTIC_SEARCH]" in raw_query:
            real_query = raw_query.replace("[MODE: SEMANTIC_SEARCH]", "").strip()
            if real_query:
                response_text = rag_chain.invoke(real_query)
            else:
                response_text = "B·∫°n vui l√≤ng nh·∫≠p n·ªôi dung c·∫ßn t√¨m ki·∫øm nh√©!"
            tool_used = "semantic"

        # --- MODE 2: TF-IDF RECOMMEND (Ph·∫ßn m·ªõi th√™m) ---
        elif "[MODE: TFIDF_RECOMMEND]" in raw_query:
            movie_title = raw_query.replace("[MODE: TFIDF_RECOMMEND]", "").strip()
            
            # Ki·ªÉm tra xem model ƒë√£ load ƒë∆∞·ª£c ch∆∞a
            if movie_recommender is None:
                response_text = "H·ªá th·ªëng ƒëang g·∫∑p s·ª± c·ªë t·∫£i d·ªØ li·ªáu g·ª£i √Ω (file pickle kh√¥ng kh·∫£ d·ª•ng)."
            else:
                # G·ªçi h√†m recommend t·ª´ object ƒë√£ load
                print(f"[TF-IDF] T√¨m ki·∫øm phim t∆∞∆°ng t·ª±: {movie_title}")
                recommendations = movie_recommender.recommend(movie_title)

                if recommendations is None:
                    response_text = f"Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y b·ªô phim **'{movie_title}'** trong c∆° s·ªü d·ªØ li·ªáu ƒë·ªÉ ƒë∆∞a ra g·ª£i √Ω."
                else:
                    # Format danh s√°ch phim tr·∫£ v·ªÅ (Kh√¥ng d√πng LLM)
                    list_items = "\n".join([f"üé¨ **{title}**" for title in recommendations])
                    response_text = (
                        f"D·ª±a tr√™n thu·∫≠t to√°n TF-IDF, d∆∞·ªõi ƒë√¢y l√† 5 b·ªô phim c√≥ n·ªôi dung/th·ªÉ lo·∫°i t∆∞∆°ng t·ª± v·ªõi **{movie_title}**:\n\n"
                        f"{list_items}"
                    )
            
            tool_used = "tfidf"

        else:
            response_text = "H·ªá th·ªëng kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c ch·∫ø ƒë·ªô. Vui l√≤ng ch·ªçn ch·∫ø ƒë·ªô t√¨m ki·∫øm."

        return jsonify({
            "response": response_text,
            "tool_used": tool_used
        })

    except Exception as e:
        print(f"‚ùå L·ªñI SERVER: {str(e)}")
        return jsonify({
            "response": f"ƒê√£ x·∫£y ra l·ªói ph√≠a server: {str(e)}",
            "tool_used": "none"
        }), 500

@app.route('/')
def home():
    return send_from_directory(current_dir, 'index.html')

if __name__ == '__main__':
    app.run(debug=True, port=5001, use_reloader=False)